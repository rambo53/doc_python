///////////////// BASE NLTK //////////////////

Le Nltk est le traitement du language naturel comme data.

Pour pouvoir utiliser la librairie "nltk" il faut utiliser Jupiter notebook (plus simple).
Importer nltk et charger les dépendances :

import nltk
nltk.download()

from nltk.corpus import stopwords
from nltk import word_tokenize

# Pour un exemple simple d'utilisation, on récupère un texte :

Sentence = 'Une bardette légère et facile d’entretien en néoprène alvéolé antidérapant. Assise matelassée néoprène, recouverte Rexine avec anneaux d’étrivières camouflés pour limiter la gêne au niveau des cuisses. Equipée d’une poignée en polypropylène et d’un anneau de croupière. Sangle et contre-sanglon double épaisseur avec œillets de renfort en polypropylène. Sangle doublée amara côté poney pour davantage de confort.'


# puis on utilise les fonctions de stop words pour éliminer de notre texte les mots inutiles, on peut ajouter les mots que nous voulons ou la ponctuation.

french_stopwords = set(stopwords.words('french'))

lst_french_ponct = [".", ",", '’']
french_stopwords.update(lst_french_ponct)

filtre_stopfr =  lambda text: [token for token in text if token.lower() not in french_stopwords]

sentence_filter = filtre_stopfr( word_tokenize(sentence, language="french") )

# une fois cette étape réalisée voilà le résultat 

['bardette',
 'légère',
 'facile',
 'entretien',
 'néoprène',
 'alvéolé',
 'antidérapant',
 'Assise',
 'matelassée',
 'néoprène',
 'recouverte',
 'Rexine',
 'anneaux',
 'étrivières',
 'camouflés',
 'limiter',
 'gêne',
 'niveau',
 'cuisses',
 'Equipée',
 'poignée',
 'polypropylène',
 'anneau',
 'croupière',
 'Sangle',
 'contre-sanglon',
 'double',
 'épaisseur',
 'œillets',
 'renfort',
 'polypropylène',
 'Sangle',
 'doublée',
 'amara',
 'côté',
 'poney',
 'davantage',
 'confort']

# on peut ensuite récupérer une fréquence de distribution de mots, afin de voir les mots apparaissant le plus souvent dans notre texte.

fd = nltk.FreqDist(sentence_filter) 
print(fd.most_common())

[('néoprène', 2), ('polypropylène', 2), ('Sangle', 2), ('bardette', 1), ('légère', 1), ('facile', 1), ('entretien', 1), ('alvéolé', 1), ('antidérapant', 1), ('Assise', 1), ('matelassée', 1), ('recouverte', 1), ('Rexine', 1), ('anneaux', 1), ('étrivières', 1), ('camouflés', 1), ('limiter', 1), ('gêne', 1), ('niveau', 1), ('cuisses', 1), ('Equipée', 1), ('poignée', 1), ('anneau', 1), ('croupière', 1), ('contre-sanglon', 1), ('double', 1), ('épaisseur', 1), ('œillets', 1), ('renfort', 1), ('doublée', 1), ('amara', 1), ('côté', 1), ('poney', 1), ('davantage', 1), ('confort', 1)]

# si l'on veut extraire les 'n' premiers mots les plus fréquents on précise dans la focntion 'most_common' par exemple les 5 premiers
print(fd.most_common(5))

# si je veux extraire la fréquence de distribution d'un mot en particulier 
fd.get("bardette")

# on peut aussi regrouper les mots ayant la même racine synthaxique

example_words = ["donner","don","donne","donnera","dons","test"]
stemmer = nltk.stem.snowball.FrenchStemmer()

for w in example_words:
    print(stemmer.stem(w))

don
don
don
don
don
test
